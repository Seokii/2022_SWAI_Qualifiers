{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/minseok_EDA2_train.csv\")\n",
    "test = pd.read_csv(\"../data/minseok_EDA2_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426321f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(method='ffill', inplace=True)\n",
    "test.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ffefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcl = train[train.columns[39:55]]\n",
    "vcl_test = test[test.columns[39:55]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dfadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcl['VCL_cal'] = vcl.sum(axis=1) / 16\n",
    "vcl_test['VCL_cal'] = vcl_test.sum(axis=1) / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd726fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, vcl['VCL_cal']], axis=1)\n",
    "test = pd.concat([test, vcl_test['VCL_cal']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43921d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in train.columns.to_list() if col not in ['nerdiness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[columns]\n",
    "target = train['nerdiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb97449",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['nerdiness'], axis=1).values\n",
    "y = train['nerdiness'].values\n",
    "#y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292889be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.to_numpy()\n",
    "# y_train = y_train.to_numpy().squeeze()\n",
    "# X_test = X_test.to_numpy()\n",
    "# y_test = y_test.to_numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = TabNetClassifier(\n",
    "#                        cat_emb_dim=5,\n",
    "#                        optimizer_fn=torch.optim.Adam,\n",
    "#                        optimizer_params=dict(lr=1e-2),\n",
    "#                        scheduler_params={\"step_size\":30,\n",
    "#                                          \"gamma\":0.9},\n",
    "#                        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "#                        mask_type='sparsemax' # \"sparsemax\", entmax\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ac40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_epochs = 50\n",
    "\n",
    "# clf.fit(\n",
    "#     X_train=X_train, y_train=y_train,\n",
    "#     eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "#     eval_name=['train', 'valid'],\n",
    "#     eval_metric=['auc'],\n",
    "#     max_epochs=max_epochs , patience=20,\n",
    "#     batch_size=2048, virtual_batch_size=256,\n",
    "#     num_workers=0,\n",
    "#     weights=1,\n",
    "#     drop_last=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b644649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(trial):\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
    "    tabnet_params = dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n",
    "                     lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type=mask_type, n_shared=n_shared,\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=trial.suggest_int(\"patienceScheduler\",low=3,high=10), # changing sheduler patience to be lower than early stopping patience \n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.5,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=0,\n",
    "                     ) #early stopping\n",
    "    kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    CV_score_array    =[]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "        clf = TabNetClassifier(**tabnet_params)\n",
    "        clf.fit(X_train=X_train, y_train=y_train,\n",
    "                  eval_set=[(X_valid, y_valid)],\n",
    "                  patience=trial.suggest_int(\"patience\",low=15,high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n",
    "                  eval_metric=['auc'])\n",
    "        CV_score_array.append(clf.best_cost)\n",
    "    avg = np.mean(CV_score_array)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ebf4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization')\n",
    "study.optimize(Objective, n_trials=20) # timeout=6*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "TabNet_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TabNet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = dict(n_d=TabNet_params['n_da'], n_a=TabNet_params['n_da'], n_steps=TabNet_params['n_steps'], gamma=TabNet_params['gamma'],\n",
    "                     lambda_sparse=TabNet_params['lambda_sparse'], optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type=TabNet_params['mask_type'], n_shared=TabNet_params['n_shared'],\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=TabNet_params['patienceScheduler'],\n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.5,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=0,\n",
    "                     )\n",
    "epochs = TabNet_params['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(**final_params)\n",
    "clf.fit(X_train=X, y_train=y,\n",
    "          patience=TabNet_params['patience'], max_epochs=epochs,\n",
    "          eval_metric=['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ceee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.values\n",
    "sub = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['nerdiness']=clf.predict(X_test)\n",
    "sub.to_csv('../submission/tabnet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12428fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
