{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b30d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7606f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/real_final_train.csv')\n",
    "test = pd.read_csv('../data/real_final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2310407a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VCL_0</th>\n",
       "      <th>VCL_38</th>\n",
       "      <th>education</th>\n",
       "      <th>urban</th>\n",
       "      <th>gender</th>\n",
       "      <th>engnat</th>\n",
       "      <th>hand</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand.1</th>\n",
       "      <th>religion.1</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>married</th>\n",
       "      <th>orientation</th>\n",
       "      <th>familysize</th>\n",
       "      <th>ASD</th>\n",
       "      <th>nerdiness</th>\n",
       "      <th>Qs</th>\n",
       "      <th>TIPI_left</th>\n",
       "      <th>TIPI_right</th>\n",
       "      <th>VCL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.346154</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.269231</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.346154</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.730769</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.884615</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VCL_0  VCL_38  education  urban  gender  engnat  hand  religion  \\\n",
       "0          2       0          2      1       3       1     2        12   \n",
       "1          1       1          4      2       2       1     1         2   \n",
       "2          1       1          2      1       1       2     1         2   \n",
       "3          2       0          1      3       1       1     2         1   \n",
       "4          2       1          1      2       2       2     2        12   \n",
       "...      ...     ...        ...    ...     ...     ...   ...       ...   \n",
       "14995      2       1          2      2       2       1     1         1   \n",
       "14996      2       0          4      1       2       2     1         3   \n",
       "14997      2       0          2      2       2       1     1         1   \n",
       "14998      2       2          3      2       2       1     1        12   \n",
       "14999      2       1          2      3       1       2     1         2   \n",
       "\n",
       "       hand.1  religion.1  age_cat  married  orientation  familysize  ASD  \\\n",
       "0           2          12        2        1            4           4    2   \n",
       "1           1           2        4        2            1           4    2   \n",
       "2           1           2        4        3            2           4    2   \n",
       "3           2           1        1        1            1           2    2   \n",
       "4           2          12        1        1            1           1    2   \n",
       "...       ...         ...      ...      ...          ...         ...  ...   \n",
       "14995       1           1        1        1            3           3    2   \n",
       "14996       1           3        4        2            1           3    2   \n",
       "14997       1           1        2        1            2           3    1   \n",
       "14998       1          12        2        2            4           2    1   \n",
       "14999       1           2        2        1            2           1    2   \n",
       "\n",
       "       nerdiness        Qs  TIPI_left  TIPI_right  VCL_1  \n",
       "0              1  2.346154       2.75    2.333333    1.0  \n",
       "1              1  2.269231       3.50    2.000000    1.0  \n",
       "2              1  2.346154       5.00    2.000000    1.0  \n",
       "3              1  2.384615       3.50    2.500000    1.0  \n",
       "4              0  2.423077       3.75    2.666667    1.0  \n",
       "...          ...       ...        ...         ...    ...  \n",
       "14995          0  2.307692       3.75    2.166667    1.0  \n",
       "14996          1  2.730769       4.25    2.500000    1.0  \n",
       "14997          1  2.884615       5.00    2.000000    1.0  \n",
       "14998          0  2.615385       4.50    2.500000    1.0  \n",
       "14999          1  2.307692       3.50    2.166667    1.0  \n",
       "\n",
       "[15000 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa01bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in train.columns.to_list() if col not in ['nerdiness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a87b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[columns]\n",
    "target = train['nerdiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b9b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, data=data, target=target):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15, random_state=777)\n",
    "    param = {\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'lambda' : trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha' : trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree' : trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        'subsample' : trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n",
    "        'learning_rate' : trial.suggest_categorical('learning_rate', [0.008, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02]),\n",
    "        'n_estimators' : 10000,\n",
    "        'max_depth' : trial.suggest_categorical('max_depth', [5, 7, 9, 11, 13, 15, 17]),\n",
    "        'random_state' : trial.suggest_categorical('random_state', [777]),\n",
    "        'min_child_weight' : trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    \n",
    "    model.fit(train_x, train_y, eval_set=[(test_x, test_y)], early_stopping_rounds=100, verbose=False)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    auc = roc_auc_score(test_y, preds)\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985d2299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:07:45,275]\u001b[0m A new study created in memory with name: no-name-66a2ac24-916c-438e-82f9-989cbc0d48df\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:07:56,931]\u001b[0m Trial 0 finished with value: 0.9934959349593495 and parameters: {'lambda': 0.006120864205992862, 'alpha': 3.9890223460013146, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 17, 'random_state': 777, 'min_child_weight': 27}. Best is trial 0 with value: 0.9934959349593495.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:04,701]\u001b[0m Trial 1 finished with value: 0.9925992348158776 and parameters: {'lambda': 0.07713588765281236, 'alpha': 2.364118870880586, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 15, 'random_state': 777, 'min_child_weight': 48}. Best is trial 1 with value: 0.9925992348158776.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:06,600]\u001b[0m Trial 2 finished with value: 0.9673362027737925 and parameters: {'lambda': 5.675832519777149, 'alpha': 0.10431344999851598, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.018, 'max_depth': 11, 'random_state': 777, 'min_child_weight': 208}. Best is trial 2 with value: 0.9673362027737925.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:11,208]\u001b[0m Trial 3 finished with value: 0.95844093735055 and parameters: {'lambda': 0.3160024158776561, 'alpha': 0.08776819095660347, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 7, 'random_state': 777, 'min_child_weight': 161}. Best is trial 3 with value: 0.95844093735055.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:14,086]\u001b[0m Trial 4 finished with value: 0.9785987565758011 and parameters: {'lambda': 0.0048658941181418175, 'alpha': 0.0021303778534601135, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 11, 'random_state': 777, 'min_child_weight': 78}. Best is trial 3 with value: 0.95844093735055.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:21,167]\u001b[0m Trial 5 finished with value: 0.9434122429459589 and parameters: {'lambda': 0.029392475967507596, 'alpha': 0.011005770411081032, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 13, 'random_state': 777, 'min_child_weight': 151}. Best is trial 5 with value: 0.9434122429459589.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:24,571]\u001b[0m Trial 6 finished with value: 0.9934959349593495 and parameters: {'lambda': 0.001335750698803229, 'alpha': 0.0018834549420799547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 777, 'min_child_weight': 30}. Best is trial 5 with value: 0.9434122429459589.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:28,194]\u001b[0m Trial 7 finished with value: 0.994296987087518 and parameters: {'lambda': 0.02088285022619671, 'alpha': 1.0086712625766807, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'random_state': 777, 'min_child_weight': 36}. Best is trial 5 with value: 0.9434122429459589.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:34,729]\u001b[0m Trial 8 finished with value: 0.8691415590626494 and parameters: {'lambda': 0.07465901737378901, 'alpha': 0.013674812669042923, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 15, 'random_state': 777, 'min_child_weight': 203}. Best is trial 8 with value: 0.8691415590626494.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:41,434]\u001b[0m Trial 9 finished with value: 0.91142993782879 and parameters: {'lambda': 0.0018791375323414946, 'alpha': 0.19149503280070632, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 7, 'random_state': 777, 'min_child_weight': 144}. Best is trial 8 with value: 0.8691415590626494.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:47,870]\u001b[0m Trial 10 finished with value: 0.7281802965088475 and parameters: {'lambda': 0.7192874427022057, 'alpha': 0.017305317538498354, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 5, 'random_state': 777, 'min_child_weight': 271}. Best is trial 10 with value: 0.7281802965088475.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:51,747]\u001b[0m Trial 11 finished with value: 0.7241750358680057 and parameters: {'lambda': 0.7362706705948139, 'alpha': 0.014608637025859234, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 5, 'random_state': 777, 'min_child_weight': 288}. Best is trial 11 with value: 0.7241750358680057.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:54,319]\u001b[0m Trial 12 finished with value: 0.7255619320899092 and parameters: {'lambda': 0.9694610575464075, 'alpha': 0.015152726434889258, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 5, 'random_state': 777, 'min_child_weight': 294}. Best is trial 11 with value: 0.7241750358680057.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:08:58,281]\u001b[0m Trial 13 finished with value: 0.7226327116212339 and parameters: {'lambda': 2.6015349393290106, 'alpha': 0.029573418216154546, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 5, 'random_state': 777, 'min_child_weight': 294}. Best is trial 13 with value: 0.7226327116212339.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:09:02,729]\u001b[0m Trial 14 finished with value: 0.8927427068388332 and parameters: {'lambda': 9.576028645044468, 'alpha': 0.049313169092160096, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 9, 'random_state': 777, 'min_child_weight': 250}. Best is trial 13 with value: 0.7226327116212339.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:09:08,483]\u001b[0m Trial 15 finished with value: 0.894846963175514 and parameters: {'lambda': 3.065047913877309, 'alpha': 0.44084713321721264, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.016, 'max_depth': 5, 'random_state': 777, 'min_child_weight': 240}. Best is trial 13 with value: 0.7226327116212339.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:09:10,839]\u001b[0m Trial 16 finished with value: 0.7271640363462459 and parameters: {'lambda': 1.7433871406065533, 'alpha': 0.0049992386620793415, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.012, 'max_depth': 5, 'random_state': 777, 'min_child_weight': 295}. Best is trial 13 with value: 0.7226327116212339.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:09:14,971]\u001b[0m Trial 17 finished with value: 0.9658656145384983 and parameters: {'lambda': 0.4317697862768644, 'alpha': 0.036785457271044236, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.012, 'max_depth': 5, 'random_state': 777, 'min_child_weight': 214}. Best is trial 13 with value: 0.7226327116212339.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:09:17,655]\u001b[0m Trial 18 finished with value: 0.9666068866571019 and parameters: {'lambda': 0.22737527750429165, 'alpha': 0.005156956698941073, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 9, 'random_state': 777, 'min_child_weight': 100}. Best is trial 13 with value: 0.7226327116212339.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 16:09:21,102]\u001b[0m Trial 19 finished with value: 0.7332496413199425 and parameters: {'lambda': 2.5559095221850097, 'alpha': 0.0010978081850679634, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 17, 'random_state': 777, 'min_child_weight': 264}. Best is trial 13 with value: 0.7226327116212339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 20\n",
      "Best trial: {'lambda': 2.6015349393290106, 'alpha': 0.029573418216154546, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 5, 'random_state': 777, 'min_child_weight': 294}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eced4634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_alpha</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_lambda</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_random_state</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.993496</td>\n",
       "      <td>2022-08-02 16:07:45.276459</td>\n",
       "      <td>2022-08-02 16:07:56.931427</td>\n",
       "      <td>0 days 00:00:11.654968</td>\n",
       "      <td>3.989022</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.008</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>777</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.992599</td>\n",
       "      <td>2022-08-02 16:07:56.932427</td>\n",
       "      <td>2022-08-02 16:08:04.701350</td>\n",
       "      <td>0 days 00:00:07.768923</td>\n",
       "      <td>2.364119</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.077136</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>777</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.967336</td>\n",
       "      <td>2022-08-02 16:08:04.702350</td>\n",
       "      <td>2022-08-02 16:08:06.600780</td>\n",
       "      <td>0 days 00:00:01.898430</td>\n",
       "      <td>0.104313</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.675833</td>\n",
       "      <td>0.018</td>\n",
       "      <td>11</td>\n",
       "      <td>208</td>\n",
       "      <td>777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.958441</td>\n",
       "      <td>2022-08-02 16:08:06.601780</td>\n",
       "      <td>2022-08-02 16:08:11.207814</td>\n",
       "      <td>0 days 00:00:04.606034</td>\n",
       "      <td>0.087768</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.316002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>777</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.978599</td>\n",
       "      <td>2022-08-02 16:08:11.208814</td>\n",
       "      <td>2022-08-02 16:08:14.085022</td>\n",
       "      <td>0 days 00:00:02.876208</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.018</td>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "      <td>777</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.943412</td>\n",
       "      <td>2022-08-02 16:08:14.086022</td>\n",
       "      <td>2022-08-02 16:08:21.166612</td>\n",
       "      <td>0 days 00:00:07.080590</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.029392</td>\n",
       "      <td>0.008</td>\n",
       "      <td>13</td>\n",
       "      <td>151</td>\n",
       "      <td>777</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.993496</td>\n",
       "      <td>2022-08-02 16:08:21.167612</td>\n",
       "      <td>2022-08-02 16:08:24.571376</td>\n",
       "      <td>0 days 00:00:03.403764</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.018</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.994297</td>\n",
       "      <td>2022-08-02 16:08:24.572376</td>\n",
       "      <td>2022-08-02 16:08:28.194189</td>\n",
       "      <td>0 days 00:00:03.621813</td>\n",
       "      <td>1.008671</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020883</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>777</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.869142</td>\n",
       "      <td>2022-08-02 16:08:28.195189</td>\n",
       "      <td>2022-08-02 16:08:34.729658</td>\n",
       "      <td>0 days 00:00:06.534469</td>\n",
       "      <td>0.013675</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.074659</td>\n",
       "      <td>0.014</td>\n",
       "      <td>15</td>\n",
       "      <td>203</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.911430</td>\n",
       "      <td>2022-08-02 16:08:34.730658</td>\n",
       "      <td>2022-08-02 16:08:41.433164</td>\n",
       "      <td>0 days 00:00:06.702506</td>\n",
       "      <td>0.191495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.014</td>\n",
       "      <td>7</td>\n",
       "      <td>144</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.728180</td>\n",
       "      <td>2022-08-02 16:08:41.434164</td>\n",
       "      <td>2022-08-02 16:08:47.870608</td>\n",
       "      <td>0 days 00:00:06.436444</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.719287</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.724175</td>\n",
       "      <td>2022-08-02 16:08:47.871608</td>\n",
       "      <td>2022-08-02 16:08:51.747478</td>\n",
       "      <td>0 days 00:00:03.875870</td>\n",
       "      <td>0.014609</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.736271</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>288</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.725562</td>\n",
       "      <td>2022-08-02 16:08:51.748478</td>\n",
       "      <td>2022-08-02 16:08:54.319320</td>\n",
       "      <td>0 days 00:00:02.570842</td>\n",
       "      <td>0.015153</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.969461</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>294</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.722633</td>\n",
       "      <td>2022-08-02 16:08:54.320320</td>\n",
       "      <td>2022-08-02 16:08:58.280215</td>\n",
       "      <td>0 days 00:00:03.959895</td>\n",
       "      <td>0.029573</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.601535</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>294</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.892743</td>\n",
       "      <td>2022-08-02 16:08:58.281215</td>\n",
       "      <td>2022-08-02 16:09:02.728218</td>\n",
       "      <td>0 days 00:00:04.447003</td>\n",
       "      <td>0.049313</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.576029</td>\n",
       "      <td>0.020</td>\n",
       "      <td>9</td>\n",
       "      <td>250</td>\n",
       "      <td>777</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.894847</td>\n",
       "      <td>2022-08-02 16:09:02.729218</td>\n",
       "      <td>2022-08-02 16:09:08.482031</td>\n",
       "      <td>0 days 00:00:05.752813</td>\n",
       "      <td>0.440847</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.065048</td>\n",
       "      <td>0.016</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>777</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.727164</td>\n",
       "      <td>2022-08-02 16:09:08.483031</td>\n",
       "      <td>2022-08-02 16:09:10.839064</td>\n",
       "      <td>0 days 00:00:02.356033</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.743387</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>295</td>\n",
       "      <td>777</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.965866</td>\n",
       "      <td>2022-08-02 16:09:10.840064</td>\n",
       "      <td>2022-08-02 16:09:14.971007</td>\n",
       "      <td>0 days 00:00:04.130943</td>\n",
       "      <td>0.036785</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.431770</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.966607</td>\n",
       "      <td>2022-08-02 16:09:14.972007</td>\n",
       "      <td>2022-08-02 16:09:17.654614</td>\n",
       "      <td>0 days 00:00:02.682607</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.227375</td>\n",
       "      <td>0.012</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.733250</td>\n",
       "      <td>2022-08-02 16:09:17.655614</td>\n",
       "      <td>2022-08-02 16:09:21.102400</td>\n",
       "      <td>0 days 00:00:03.446786</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.555910</td>\n",
       "      <td>0.016</td>\n",
       "      <td>17</td>\n",
       "      <td>264</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.993496 2022-08-02 16:07:45.276459 2022-08-02 16:07:56.931427   \n",
       "1        1  0.992599 2022-08-02 16:07:56.932427 2022-08-02 16:08:04.701350   \n",
       "2        2  0.967336 2022-08-02 16:08:04.702350 2022-08-02 16:08:06.600780   \n",
       "3        3  0.958441 2022-08-02 16:08:06.601780 2022-08-02 16:08:11.207814   \n",
       "4        4  0.978599 2022-08-02 16:08:11.208814 2022-08-02 16:08:14.085022   \n",
       "5        5  0.943412 2022-08-02 16:08:14.086022 2022-08-02 16:08:21.166612   \n",
       "6        6  0.993496 2022-08-02 16:08:21.167612 2022-08-02 16:08:24.571376   \n",
       "7        7  0.994297 2022-08-02 16:08:24.572376 2022-08-02 16:08:28.194189   \n",
       "8        8  0.869142 2022-08-02 16:08:28.195189 2022-08-02 16:08:34.729658   \n",
       "9        9  0.911430 2022-08-02 16:08:34.730658 2022-08-02 16:08:41.433164   \n",
       "10      10  0.728180 2022-08-02 16:08:41.434164 2022-08-02 16:08:47.870608   \n",
       "11      11  0.724175 2022-08-02 16:08:47.871608 2022-08-02 16:08:51.747478   \n",
       "12      12  0.725562 2022-08-02 16:08:51.748478 2022-08-02 16:08:54.319320   \n",
       "13      13  0.722633 2022-08-02 16:08:54.320320 2022-08-02 16:08:58.280215   \n",
       "14      14  0.892743 2022-08-02 16:08:58.281215 2022-08-02 16:09:02.728218   \n",
       "15      15  0.894847 2022-08-02 16:09:02.729218 2022-08-02 16:09:08.482031   \n",
       "16      16  0.727164 2022-08-02 16:09:08.483031 2022-08-02 16:09:10.839064   \n",
       "17      17  0.965866 2022-08-02 16:09:10.840064 2022-08-02 16:09:14.971007   \n",
       "18      18  0.966607 2022-08-02 16:09:14.972007 2022-08-02 16:09:17.654614   \n",
       "19      19  0.733250 2022-08-02 16:09:17.655614 2022-08-02 16:09:21.102400   \n",
       "\n",
       "                 duration  params_alpha  params_colsample_bytree  \\\n",
       "0  0 days 00:00:11.654968      3.989022                      0.4   \n",
       "1  0 days 00:00:07.768923      2.364119                      0.4   \n",
       "2  0 days 00:00:01.898430      0.104313                      0.6   \n",
       "3  0 days 00:00:04.606034      0.087768                      0.9   \n",
       "4  0 days 00:00:02.876208      0.002130                      0.8   \n",
       "5  0 days 00:00:07.080590      0.011006                      0.5   \n",
       "6  0 days 00:00:03.403764      0.001883                      0.8   \n",
       "7  0 days 00:00:03.621813      1.008671                      0.8   \n",
       "8  0 days 00:00:06.534469      0.013675                      0.5   \n",
       "9  0 days 00:00:06.702506      0.191495                      1.0   \n",
       "10 0 days 00:00:06.436444      0.017305                      0.3   \n",
       "11 0 days 00:00:03.875870      0.014609                      0.3   \n",
       "12 0 days 00:00:02.570842      0.015153                      0.3   \n",
       "13 0 days 00:00:03.959895      0.029573                      0.3   \n",
       "14 0 days 00:00:04.447003      0.049313                      0.3   \n",
       "15 0 days 00:00:05.752813      0.440847                      0.7   \n",
       "16 0 days 00:00:02.356033      0.004999                      0.3   \n",
       "17 0 days 00:00:04.130943      0.036785                      0.3   \n",
       "18 0 days 00:00:02.682607      0.005157                      1.0   \n",
       "19 0 days 00:00:03.446786      0.001098                      0.7   \n",
       "\n",
       "    params_lambda  params_learning_rate  params_max_depth  \\\n",
       "0        0.006121                 0.008                17   \n",
       "1        0.077136                 0.010                15   \n",
       "2        5.675833                 0.018                11   \n",
       "3        0.316002                 0.008                 7   \n",
       "4        0.004866                 0.018                11   \n",
       "5        0.029392                 0.008                13   \n",
       "6        0.001336                 0.018                13   \n",
       "7        0.020883                 0.010                15   \n",
       "8        0.074659                 0.014                15   \n",
       "9        0.001879                 0.014                 7   \n",
       "10       0.719287                 0.012                 5   \n",
       "11       0.736271                 0.012                 5   \n",
       "12       0.969461                 0.012                 5   \n",
       "13       2.601535                 0.012                 5   \n",
       "14       9.576029                 0.020                 9   \n",
       "15       3.065048                 0.016                 5   \n",
       "16       1.743387                 0.012                 5   \n",
       "17       0.431770                 0.012                 5   \n",
       "18       0.227375                 0.012                 9   \n",
       "19       2.555910                 0.016                17   \n",
       "\n",
       "    params_min_child_weight  params_random_state  params_subsample     state  \n",
       "0                        27                  777               0.4  COMPLETE  \n",
       "1                        48                  777               0.6  COMPLETE  \n",
       "2                       208                  777               1.0  COMPLETE  \n",
       "3                       161                  777               0.7  COMPLETE  \n",
       "4                        78                  777               0.6  COMPLETE  \n",
       "5                       151                  777               0.6  COMPLETE  \n",
       "6                        30                  777               0.5  COMPLETE  \n",
       "7                        36                  777               0.8  COMPLETE  \n",
       "8                       203                  777               0.5  COMPLETE  \n",
       "9                       144                  777               0.5  COMPLETE  \n",
       "10                      271                  777               0.5  COMPLETE  \n",
       "11                      288                  777               0.5  COMPLETE  \n",
       "12                      294                  777               0.5  COMPLETE  \n",
       "13                      294                  777               0.5  COMPLETE  \n",
       "14                      250                  777               0.8  COMPLETE  \n",
       "15                      240                  777               0.7  COMPLETE  \n",
       "16                      295                  777               0.4  COMPLETE  \n",
       "17                      214                  777               1.0  COMPLETE  \n",
       "18                      100                  777               0.5  COMPLETE  \n",
       "19                      264                  777               0.5  COMPLETE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e84784c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda': 2.6015349393290106,\n",
       " 'alpha': 0.029573418216154546,\n",
       " 'colsample_bytree': 0.3,\n",
       " 'subsample': 0.5,\n",
       " 'learning_rate': 0.012,\n",
       " 'max_depth': 5,\n",
       " 'random_state': 777,\n",
       " 'min_child_weight': 294,\n",
       " 'n_estimators': 10000,\n",
       " 'tree_method': 'gpu_hist'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_trial = study.best_trial.params\n",
    "Best_trial[\"n_estimators\"], Best_trial[\"tree_method\"] = 10000, 'gpu_hist'\n",
    "Best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a22802b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fold: 1 ==> auc: 0.7391350072538153\n",
      "[16:11:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2 ==> auc: 0.7428133809003612\n",
      "[16:12:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3 ==> auc: 0.7244283908772333\n",
      "[16:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 4 ==> auc: 0.7360031098914392\n",
      "[16:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 5 ==> auc: 0.743615248950527\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros(test.shape[0])\n",
    "kf = KFold(n_splits=5, random_state=777, shuffle=True)\n",
    "auc=[]\n",
    "n=0\n",
    "for trn_idx, test_idx in kf.split(train[columns], train['nerdiness']):\n",
    "    X_tr, X_val = train[columns].iloc[trn_idx], train[columns].iloc[test_idx]\n",
    "    y_tr, y_val = train['nerdiness'].iloc[trn_idx], train['nerdiness'].iloc[test_idx]\n",
    "    model = xgb.XGBClassifier(**Best_trial)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "    preds += model.predict(test[columns])/kf.n_splits\n",
    "    auc.append(roc_auc_score(y_val, model.predict(X_val)))\n",
    "    print(f'fold: {n+1} ==> auc: {auc[n]}')\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84d8aee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7371990275746751"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "808bdd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "581af47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35452"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98c45231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3da6a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nerdiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  nerdiness\n",
       "0      0         -1\n",
       "1      1         -1\n",
       "2      2         -1\n",
       "3      3         -1\n",
       "4      4         -1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "467969f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['nerdiness']=preds\n",
    "sub.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26f35fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35452, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
