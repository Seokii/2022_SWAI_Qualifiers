{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5200b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7686a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/real_final_train.csv')\n",
    "test = pd.read_csv('../data/real_final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47102a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VCL_0</th>\n",
       "      <th>VCL_38</th>\n",
       "      <th>education</th>\n",
       "      <th>urban</th>\n",
       "      <th>gender</th>\n",
       "      <th>engnat</th>\n",
       "      <th>hand</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand.1</th>\n",
       "      <th>religion.1</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>married</th>\n",
       "      <th>orientation</th>\n",
       "      <th>familysize</th>\n",
       "      <th>ASD</th>\n",
       "      <th>nerdiness</th>\n",
       "      <th>Qs</th>\n",
       "      <th>TIPI_left</th>\n",
       "      <th>TIPI_right</th>\n",
       "      <th>VCL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.346154</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.269231</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.346154</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.730769</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.884615</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VCL_0  VCL_38  education  urban  gender  engnat  hand  religion  \\\n",
       "0          2       0          2      1       3       1     2        12   \n",
       "1          1       1          4      2       2       1     1         2   \n",
       "2          1       1          2      1       1       2     1         2   \n",
       "3          2       0          1      3       1       1     2         1   \n",
       "4          2       1          1      2       2       2     2        12   \n",
       "...      ...     ...        ...    ...     ...     ...   ...       ...   \n",
       "14995      2       1          2      2       2       1     1         1   \n",
       "14996      2       0          4      1       2       2     1         3   \n",
       "14997      2       0          2      2       2       1     1         1   \n",
       "14998      2       2          3      2       2       1     1        12   \n",
       "14999      2       1          2      3       1       2     1         2   \n",
       "\n",
       "       hand.1  religion.1  age_cat  married  orientation  familysize  ASD  \\\n",
       "0           2          12        2        1            4           4    2   \n",
       "1           1           2        4        2            1           4    2   \n",
       "2           1           2        4        3            2           4    2   \n",
       "3           2           1        1        1            1           2    2   \n",
       "4           2          12        1        1            1           1    2   \n",
       "...       ...         ...      ...      ...          ...         ...  ...   \n",
       "14995       1           1        1        1            3           3    2   \n",
       "14996       1           3        4        2            1           3    2   \n",
       "14997       1           1        2        1            2           3    1   \n",
       "14998       1          12        2        2            4           2    1   \n",
       "14999       1           2        2        1            2           1    2   \n",
       "\n",
       "       nerdiness        Qs  TIPI_left  TIPI_right  VCL_1  \n",
       "0              1  2.346154       2.75    2.333333    1.0  \n",
       "1              1  2.269231       3.50    2.000000    1.0  \n",
       "2              1  2.346154       5.00    2.000000    1.0  \n",
       "3              1  2.384615       3.50    2.500000    1.0  \n",
       "4              0  2.423077       3.75    2.666667    1.0  \n",
       "...          ...       ...        ...         ...    ...  \n",
       "14995          0  2.307692       3.75    2.166667    1.0  \n",
       "14996          1  2.730769       4.25    2.500000    1.0  \n",
       "14997          1  2.884615       5.00    2.000000    1.0  \n",
       "14998          0  2.615385       4.50    2.500000    1.0  \n",
       "14999          1  2.307692       3.50    2.166667    1.0  \n",
       "\n",
       "[15000 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094dbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in train.columns.to_list() if col not in ['nerdiness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a73c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[columns]\n",
    "target = train['nerdiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c7420b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, data=data, target=target):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15, random_state=777)\n",
    "    param = {\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'lambda' : trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha' : trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree' : trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        'subsample' : trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n",
    "        'learning_rate' : trial.suggest_categorical('learning_rate', [0.008, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02]),\n",
    "        'n_estimators' : 10000,\n",
    "        'max_depth' : trial.suggest_categorical('max_depth', [5, 7, 9, 11, 13, 15, 17]),\n",
    "        'random_state' : trial.suggest_categorical('random_state', [777]),\n",
    "        'min_child_weight' : trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    \n",
    "    model.fit(train_x, train_y, eval_set=[(test_x, test_y)], early_stopping_rounds=100, verbose=False)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    auc = auc(test_y, preds)\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2da92bdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-02 17:05:49,573]\u001b[0m A new study created in memory with name: no-name-8eaef033-6627-435b-90b8-c27a26603503\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-08-02 17:05:57,112]\u001b[0m Trial 0 failed because of the following error: UnboundLocalError(\"local variable 'auc' referenced before assignment\")\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Home\\AppData\\Roaming\\Python\\Python38\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Home\\AppData\\Local\\Temp/ipykernel_6120/102249080.py\", line 21, in objective\n",
      "    auc = auc(test_y, preds)\n",
      "UnboundLocalError: local variable 'auc' referenced before assignment\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'auc' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6120/2646166423.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minimize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Number of finished trials:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    398\u001b[0m             )\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6120/102249080.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial, data, target)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'auc' referenced before assignment"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32019dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_alpha</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_lambda</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_random_state</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.993496</td>\n",
       "      <td>2022-08-02 16:07:45.276459</td>\n",
       "      <td>2022-08-02 16:07:56.931427</td>\n",
       "      <td>0 days 00:00:11.654968</td>\n",
       "      <td>3.989022</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.008</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>777</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.992599</td>\n",
       "      <td>2022-08-02 16:07:56.932427</td>\n",
       "      <td>2022-08-02 16:08:04.701350</td>\n",
       "      <td>0 days 00:00:07.768923</td>\n",
       "      <td>2.364119</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.077136</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>777</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.967336</td>\n",
       "      <td>2022-08-02 16:08:04.702350</td>\n",
       "      <td>2022-08-02 16:08:06.600780</td>\n",
       "      <td>0 days 00:00:01.898430</td>\n",
       "      <td>0.104313</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.675833</td>\n",
       "      <td>0.018</td>\n",
       "      <td>11</td>\n",
       "      <td>208</td>\n",
       "      <td>777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.958441</td>\n",
       "      <td>2022-08-02 16:08:06.601780</td>\n",
       "      <td>2022-08-02 16:08:11.207814</td>\n",
       "      <td>0 days 00:00:04.606034</td>\n",
       "      <td>0.087768</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.316002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>777</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.978599</td>\n",
       "      <td>2022-08-02 16:08:11.208814</td>\n",
       "      <td>2022-08-02 16:08:14.085022</td>\n",
       "      <td>0 days 00:00:02.876208</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.018</td>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "      <td>777</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.943412</td>\n",
       "      <td>2022-08-02 16:08:14.086022</td>\n",
       "      <td>2022-08-02 16:08:21.166612</td>\n",
       "      <td>0 days 00:00:07.080590</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.029392</td>\n",
       "      <td>0.008</td>\n",
       "      <td>13</td>\n",
       "      <td>151</td>\n",
       "      <td>777</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.993496</td>\n",
       "      <td>2022-08-02 16:08:21.167612</td>\n",
       "      <td>2022-08-02 16:08:24.571376</td>\n",
       "      <td>0 days 00:00:03.403764</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.018</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.994297</td>\n",
       "      <td>2022-08-02 16:08:24.572376</td>\n",
       "      <td>2022-08-02 16:08:28.194189</td>\n",
       "      <td>0 days 00:00:03.621813</td>\n",
       "      <td>1.008671</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020883</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>777</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.869142</td>\n",
       "      <td>2022-08-02 16:08:28.195189</td>\n",
       "      <td>2022-08-02 16:08:34.729658</td>\n",
       "      <td>0 days 00:00:06.534469</td>\n",
       "      <td>0.013675</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.074659</td>\n",
       "      <td>0.014</td>\n",
       "      <td>15</td>\n",
       "      <td>203</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.911430</td>\n",
       "      <td>2022-08-02 16:08:34.730658</td>\n",
       "      <td>2022-08-02 16:08:41.433164</td>\n",
       "      <td>0 days 00:00:06.702506</td>\n",
       "      <td>0.191495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.014</td>\n",
       "      <td>7</td>\n",
       "      <td>144</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.728180</td>\n",
       "      <td>2022-08-02 16:08:41.434164</td>\n",
       "      <td>2022-08-02 16:08:47.870608</td>\n",
       "      <td>0 days 00:00:06.436444</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.719287</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.724175</td>\n",
       "      <td>2022-08-02 16:08:47.871608</td>\n",
       "      <td>2022-08-02 16:08:51.747478</td>\n",
       "      <td>0 days 00:00:03.875870</td>\n",
       "      <td>0.014609</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.736271</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>288</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.725562</td>\n",
       "      <td>2022-08-02 16:08:51.748478</td>\n",
       "      <td>2022-08-02 16:08:54.319320</td>\n",
       "      <td>0 days 00:00:02.570842</td>\n",
       "      <td>0.015153</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.969461</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>294</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.722633</td>\n",
       "      <td>2022-08-02 16:08:54.320320</td>\n",
       "      <td>2022-08-02 16:08:58.280215</td>\n",
       "      <td>0 days 00:00:03.959895</td>\n",
       "      <td>0.029573</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.601535</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>294</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.892743</td>\n",
       "      <td>2022-08-02 16:08:58.281215</td>\n",
       "      <td>2022-08-02 16:09:02.728218</td>\n",
       "      <td>0 days 00:00:04.447003</td>\n",
       "      <td>0.049313</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.576029</td>\n",
       "      <td>0.020</td>\n",
       "      <td>9</td>\n",
       "      <td>250</td>\n",
       "      <td>777</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.894847</td>\n",
       "      <td>2022-08-02 16:09:02.729218</td>\n",
       "      <td>2022-08-02 16:09:08.482031</td>\n",
       "      <td>0 days 00:00:05.752813</td>\n",
       "      <td>0.440847</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.065048</td>\n",
       "      <td>0.016</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>777</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.727164</td>\n",
       "      <td>2022-08-02 16:09:08.483031</td>\n",
       "      <td>2022-08-02 16:09:10.839064</td>\n",
       "      <td>0 days 00:00:02.356033</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.743387</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>295</td>\n",
       "      <td>777</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.965866</td>\n",
       "      <td>2022-08-02 16:09:10.840064</td>\n",
       "      <td>2022-08-02 16:09:14.971007</td>\n",
       "      <td>0 days 00:00:04.130943</td>\n",
       "      <td>0.036785</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.431770</td>\n",
       "      <td>0.012</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.966607</td>\n",
       "      <td>2022-08-02 16:09:14.972007</td>\n",
       "      <td>2022-08-02 16:09:17.654614</td>\n",
       "      <td>0 days 00:00:02.682607</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.227375</td>\n",
       "      <td>0.012</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.733250</td>\n",
       "      <td>2022-08-02 16:09:17.655614</td>\n",
       "      <td>2022-08-02 16:09:21.102400</td>\n",
       "      <td>0 days 00:00:03.446786</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.555910</td>\n",
       "      <td>0.016</td>\n",
       "      <td>17</td>\n",
       "      <td>264</td>\n",
       "      <td>777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.993496 2022-08-02 16:07:45.276459 2022-08-02 16:07:56.931427   \n",
       "1        1  0.992599 2022-08-02 16:07:56.932427 2022-08-02 16:08:04.701350   \n",
       "2        2  0.967336 2022-08-02 16:08:04.702350 2022-08-02 16:08:06.600780   \n",
       "3        3  0.958441 2022-08-02 16:08:06.601780 2022-08-02 16:08:11.207814   \n",
       "4        4  0.978599 2022-08-02 16:08:11.208814 2022-08-02 16:08:14.085022   \n",
       "5        5  0.943412 2022-08-02 16:08:14.086022 2022-08-02 16:08:21.166612   \n",
       "6        6  0.993496 2022-08-02 16:08:21.167612 2022-08-02 16:08:24.571376   \n",
       "7        7  0.994297 2022-08-02 16:08:24.572376 2022-08-02 16:08:28.194189   \n",
       "8        8  0.869142 2022-08-02 16:08:28.195189 2022-08-02 16:08:34.729658   \n",
       "9        9  0.911430 2022-08-02 16:08:34.730658 2022-08-02 16:08:41.433164   \n",
       "10      10  0.728180 2022-08-02 16:08:41.434164 2022-08-02 16:08:47.870608   \n",
       "11      11  0.724175 2022-08-02 16:08:47.871608 2022-08-02 16:08:51.747478   \n",
       "12      12  0.725562 2022-08-02 16:08:51.748478 2022-08-02 16:08:54.319320   \n",
       "13      13  0.722633 2022-08-02 16:08:54.320320 2022-08-02 16:08:58.280215   \n",
       "14      14  0.892743 2022-08-02 16:08:58.281215 2022-08-02 16:09:02.728218   \n",
       "15      15  0.894847 2022-08-02 16:09:02.729218 2022-08-02 16:09:08.482031   \n",
       "16      16  0.727164 2022-08-02 16:09:08.483031 2022-08-02 16:09:10.839064   \n",
       "17      17  0.965866 2022-08-02 16:09:10.840064 2022-08-02 16:09:14.971007   \n",
       "18      18  0.966607 2022-08-02 16:09:14.972007 2022-08-02 16:09:17.654614   \n",
       "19      19  0.733250 2022-08-02 16:09:17.655614 2022-08-02 16:09:21.102400   \n",
       "\n",
       "                 duration  params_alpha  params_colsample_bytree  \\\n",
       "0  0 days 00:00:11.654968      3.989022                      0.4   \n",
       "1  0 days 00:00:07.768923      2.364119                      0.4   \n",
       "2  0 days 00:00:01.898430      0.104313                      0.6   \n",
       "3  0 days 00:00:04.606034      0.087768                      0.9   \n",
       "4  0 days 00:00:02.876208      0.002130                      0.8   \n",
       "5  0 days 00:00:07.080590      0.011006                      0.5   \n",
       "6  0 days 00:00:03.403764      0.001883                      0.8   \n",
       "7  0 days 00:00:03.621813      1.008671                      0.8   \n",
       "8  0 days 00:00:06.534469      0.013675                      0.5   \n",
       "9  0 days 00:00:06.702506      0.191495                      1.0   \n",
       "10 0 days 00:00:06.436444      0.017305                      0.3   \n",
       "11 0 days 00:00:03.875870      0.014609                      0.3   \n",
       "12 0 days 00:00:02.570842      0.015153                      0.3   \n",
       "13 0 days 00:00:03.959895      0.029573                      0.3   \n",
       "14 0 days 00:00:04.447003      0.049313                      0.3   \n",
       "15 0 days 00:00:05.752813      0.440847                      0.7   \n",
       "16 0 days 00:00:02.356033      0.004999                      0.3   \n",
       "17 0 days 00:00:04.130943      0.036785                      0.3   \n",
       "18 0 days 00:00:02.682607      0.005157                      1.0   \n",
       "19 0 days 00:00:03.446786      0.001098                      0.7   \n",
       "\n",
       "    params_lambda  params_learning_rate  params_max_depth  \\\n",
       "0        0.006121                 0.008                17   \n",
       "1        0.077136                 0.010                15   \n",
       "2        5.675833                 0.018                11   \n",
       "3        0.316002                 0.008                 7   \n",
       "4        0.004866                 0.018                11   \n",
       "5        0.029392                 0.008                13   \n",
       "6        0.001336                 0.018                13   \n",
       "7        0.020883                 0.010                15   \n",
       "8        0.074659                 0.014                15   \n",
       "9        0.001879                 0.014                 7   \n",
       "10       0.719287                 0.012                 5   \n",
       "11       0.736271                 0.012                 5   \n",
       "12       0.969461                 0.012                 5   \n",
       "13       2.601535                 0.012                 5   \n",
       "14       9.576029                 0.020                 9   \n",
       "15       3.065048                 0.016                 5   \n",
       "16       1.743387                 0.012                 5   \n",
       "17       0.431770                 0.012                 5   \n",
       "18       0.227375                 0.012                 9   \n",
       "19       2.555910                 0.016                17   \n",
       "\n",
       "    params_min_child_weight  params_random_state  params_subsample     state  \n",
       "0                        27                  777               0.4  COMPLETE  \n",
       "1                        48                  777               0.6  COMPLETE  \n",
       "2                       208                  777               1.0  COMPLETE  \n",
       "3                       161                  777               0.7  COMPLETE  \n",
       "4                        78                  777               0.6  COMPLETE  \n",
       "5                       151                  777               0.6  COMPLETE  \n",
       "6                        30                  777               0.5  COMPLETE  \n",
       "7                        36                  777               0.8  COMPLETE  \n",
       "8                       203                  777               0.5  COMPLETE  \n",
       "9                       144                  777               0.5  COMPLETE  \n",
       "10                      271                  777               0.5  COMPLETE  \n",
       "11                      288                  777               0.5  COMPLETE  \n",
       "12                      294                  777               0.5  COMPLETE  \n",
       "13                      294                  777               0.5  COMPLETE  \n",
       "14                      250                  777               0.8  COMPLETE  \n",
       "15                      240                  777               0.7  COMPLETE  \n",
       "16                      295                  777               0.4  COMPLETE  \n",
       "17                      214                  777               1.0  COMPLETE  \n",
       "18                      100                  777               0.5  COMPLETE  \n",
       "19                      264                  777               0.5  COMPLETE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fca0eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda': 2.6015349393290106,\n",
       " 'alpha': 0.029573418216154546,\n",
       " 'colsample_bytree': 0.3,\n",
       " 'subsample': 0.5,\n",
       " 'learning_rate': 0.012,\n",
       " 'max_depth': 5,\n",
       " 'random_state': 777,\n",
       " 'min_child_weight': 294,\n",
       " 'n_estimators': 10000,\n",
       " 'tree_method': 'gpu_hist'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_trial = study.best_trial.params\n",
    "Best_trial[\"n_estimators\"], Best_trial[\"tree_method\"] = 10000, 'gpu_hist'\n",
    "Best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b797e67e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fold: 1 ==> auc: 0.7391350072538153\n",
      "[16:11:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2 ==> auc: 0.7428133809003612\n",
      "[16:12:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3 ==> auc: 0.7244283908772333\n",
      "[16:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 4 ==> auc: 0.7360031098914392\n",
      "[16:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 5 ==> auc: 0.743615248950527\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros(test.shape[0])\n",
    "kf = KFold(n_splits=5, random_state=777, shuffle=True)\n",
    "auc=[]\n",
    "n=0\n",
    "for trn_idx, test_idx in kf.split(train[columns], train['nerdiness']):\n",
    "    X_tr, X_val = train[columns].iloc[trn_idx], train[columns].iloc[test_idx]\n",
    "    y_tr, y_val = train['nerdiness'].iloc[trn_idx], train['nerdiness'].iloc[test_idx]\n",
    "    model = xgb.XGBClassifier(**Best_trial)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "    preds += model.predict(test[columns])/kf.n_splits\n",
    "    auc.append(roc_auc_score(y_val, model.predict(X_val)))\n",
    "    print(f'fold: {n+1} ==> auc: {auc[n]}')\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f3b7378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7371990275746751"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7c38127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0720c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35452"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "473dc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6072ca8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nerdiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  nerdiness\n",
       "0      0         -1\n",
       "1      1         -1\n",
       "2      2         -1\n",
       "3      3         -1\n",
       "4      4         -1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52d15f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['nerdiness']=preds\n",
    "sub.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e66f9b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35452, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
